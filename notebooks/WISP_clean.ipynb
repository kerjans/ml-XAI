{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf42911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/mlr-xai\")\n",
    "\n",
    "\n",
    "from xai_selfies.WISP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "import rdkit\n",
    "print(rdkit.__version__)\n",
    "\n",
    "import shap\n",
    "print(shap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffe634",
   "metadata": {},
   "source": [
    "# To create Interative Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ae5d4",
   "metadata": {},
   "source": [
    "Interaktiv: \\\n",
    "Input als felder zum Text eingeben \\\n",
    "Model verf√ºgbar? - Wo? - Feature function welche auf smiles arbeitet? \\\n",
    "Soll die explainability auch auf unbekannten daten arbeiten? - Test/Train split weg lassen?\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6507e",
   "metadata": {},
   "source": [
    "# DO WISP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import inspect\n",
    "\n",
    "def WISP(working_dir, input_dir, ID_Column_Name, Smiles_Column_Name, Target_Column_Name, model_available=False):\n",
    "    '''\n",
    "    If you have your model available please place it in the working_dir as model.pkl\n",
    "    Input as comma seperated file\n",
    "    '''\n",
    "    #Interactive questions\n",
    "    print('Do you already have a model you want to use for the evaluation?')\n",
    "    if model_available is not None:\n",
    "        print('Please provide the name of the function to create the features based on smiles as input:')\n",
    "        function_name = input().strip()\n",
    "        feature_function = globals()[function_name]\n",
    "\n",
    "    #Load Data\n",
    "    data = pd.read_csv(input_dir)\n",
    "    data.rename(columns={ID_Column_Name: 'ID'}, inplace=True)\n",
    "\n",
    "    #Preprocessing/Standadizing\n",
    "    std = Standardizer(max_num_atoms=1000,#tipp jan: 100\n",
    "                   max_num_tautomers=10,\n",
    "                   include_stereoinfo=False,\n",
    "                   keep_largest_fragment=True, \n",
    "                   canonicalize_tautomers=True, \n",
    "                   normalize=True, \n",
    "                   sanitize_mol=True)\n",
    "    data[\"smiles_std\"] = data[Smiles_Column_Name].apply(lambda smi: std(smi)[0]) \n",
    "\n",
    "    #save data in smi format\n",
    "    data[['smiles_std', 'ID', Target_Column_Name]].to_csv(working_dir + \"data.smi\", sep='\\t', index=False, header=False)\n",
    "\n",
    "    if model_available is None:\n",
    "\n",
    "        #Calculate Fingerprints as Descriptors\n",
    "        data['Morgan_Fingerprint 2048Bit 2rad'] = data['smiles_std'].apply(get_morgan_fingerprint)\n",
    "        data['MACCS_Fingerprint'] = data['smiles_std'].apply(get_MACCS_fingerprint)\n",
    "        data['RDK_Fingerprint'] = data['smiles_std'].apply(get_RDK_fingerprint)\n",
    "\n",
    "        #test/train split\n",
    "        nr_test_samples = round(len(data) / 5) # 80/20 split\n",
    "        test = data.sample(n=nr_test_samples, random_state=6)\n",
    "        target_test = test[Target_Column_Name].values\n",
    "        train = data.drop(test.index)\n",
    "        plot_histogram(test, train,  Target_Column_Name, 'Exp.', 'Stucture Count', 'Test Set', 'Train Set',  working_dir + 'Count-Bins-test-train.png')\n",
    "\n",
    "        #settings to find best model\n",
    "        ALLfeatureCOLUMS = ['Morgan_Fingerprint 2048Bit 2rad',\n",
    "                    'RDK_Fingerprint',\n",
    "                    'MACCS_Fingerprint']\n",
    "        \n",
    "        model_types = [MLPRegressor(), \n",
    "               BayesianRidge(), \n",
    "               Lasso(), \n",
    "               GradientBoostingRegressor(), \n",
    "               LinearRegression(), \n",
    "               RandomForestRegressor(), \n",
    "               SVR(),\n",
    "               GaussianProcessRegressor(kernel=Matern())]\n",
    "        \n",
    "        #find best model\n",
    "        results = []\n",
    "\n",
    "        for model_arc in model_types:          \n",
    "            for feature in ALLfeatureCOLUMS:\n",
    "                model, r2, R2, MAE, RMSE = hp_search_helper(model_arc,train,Target_Column_Name,[str(feature)])\n",
    "                results.append({'Feature': feature,'Model_Type': model_arc,'Model': model,'r2': r2,'R2': R2,'MAE': MAE,'RMSE': RMSE})\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        best_model_row = results_df.loc[results_df['MAE'].idxmin()]\n",
    "        model = best_model_row['Model']\n",
    "        print('Best Model: ', best_model_row['Model'])\n",
    "        print('With a MAE of: ', best_model_row['MAE'])\n",
    "        print('Feature: ', best_model_row['Feature'])\n",
    "\n",
    "        #pick feature function\n",
    "        if best_model_row['Feature'] == 'Morgan_Fingerprint 2048Bit 2rad':\n",
    "            feature_function = get_morgan_fingerprint\n",
    "        if best_model_row['Feature'] == 'RDK_Fingerprint':\n",
    "            feature_function = get_RDK_fingerprint\n",
    "        if best_model_row['Feature'] == 'MACCS_Fingerprint':\n",
    "            feature_function = get_MACCS_fingerprint\n",
    "\n",
    "        #train model on trining set\n",
    "        featureCOLUMS = [best_model_row['Feature']]\n",
    "\n",
    "        prep_train = get_features(train, featureCOLUMS)\n",
    "        target_train = train[Target_Column_Name].values\n",
    "        model.fit(prep_train, target_train)\n",
    "\n",
    "        #performance on test set\n",
    "        prep_test = get_features(test, featureCOLUMS)\n",
    "        predictions = model.predict(prep_test)\n",
    "\n",
    "        #statistic on testset\n",
    "        r2 = np.corrcoef(target_test.flatten(), predictions.flatten())[0,1]**2\n",
    "        RMSE_z = np.sqrt(np.mean((target_test.flatten() - predictions.flatten())**2))\n",
    "        RMSE_n = np.sqrt(np.mean((target_test.flatten() - np.mean(target_test.flatten()))**2))\n",
    "        R2 = 1 - RMSE_z**2/RMSE_n**2\n",
    "        MAE = mean_absolute_error(target_test.flatten(), predictions.flatten())\n",
    "        max_err = max_error(target_test.flatten(), predictions.flatten())\n",
    "        mse = mean_squared_error(target_test.flatten(), predictions.flatten())\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        #print/plot results\n",
    "        print('Performance on testset(r2, R2, MAE, RMSE, Maximal Error, MSE):',r2,';',R2,';',MAE,';',rmse,';',max_err,';', mse)\n",
    "\n",
    "        r2 = np.corrcoef(predictions, target_test)[0,1]**2\n",
    "        plot_2D(['r$^2$ = ' + str(f\"{r2:.2f}\")], 'upper left', predictions , target_test,\n",
    "                'predicted', 'experimental', working_dir + '20-80-split-true-pred.png', '#A43341', \n",
    "                include_line=False, line_style='None')\n",
    "        \n",
    "        #save model training results\n",
    "        results_df.to_csv(working_dir + \"Grid-Search.csv\", index=False)\n",
    "        pickle.dump(model, open(working_dir + \"model.pkl\", \"wb\"))\n",
    "    \n",
    "    #load the provided or just trained model\n",
    "    model = pickle.load(open(working_dir + \"model.pkl\", 'rb'))\n",
    "\n",
    "    #Attribute Atoms\n",
    "    Attribution_Colums = ['Atom Attributions']#, 'Path Attributions', 'Dropout Attributions'\n",
    "    color_coding =['#10384f'] #,'#89d329','#00bcff'\n",
    "    \n",
    "    #model/descriptor agnostic\n",
    "    data['Atom Attributions'] = data['smiles_std'].apply(lambda s: attribute_atoms(s, model, feature_function))\n",
    "    #data['Dropout Attributions'] = data['smiles_std'].apply(lambda s: attribute_atoms_dropout(s, model, feature_function))\n",
    "    #data['Path Attributions'] = data['smiles_std'].apply(lambda s: attribute_atoms_paths(s, model, feature_function))\n",
    "    \n",
    "    #SHAP explainer\n",
    "    if \"Morgan\" in inspect.getsource(feature_function):#to only use on Morgan\n",
    "        data['Morgan_Fingerprint 2048Bit 2rad'] = data['smiles_std'].apply(feature_function)\n",
    "        #pick explainer\n",
    "        model_type = model.named_steps['model'].__class__.__name__\n",
    "        if model_type in ['GradientBoostingRegressor', 'RandomForestRegressor']:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        if model_type in ['MLPRegressor', 'SVR', 'GaussianProcessRegressor'] :\n",
    "            prep_data = get_features(data, ['Morgan_Fingerprint 2048Bit 2rad'])\n",
    "            explainer = shap.KernelExplainer(model.predict, model.named_steps['scaler'].transform(prep_data))\n",
    "        if model_type in ['BayesianRidge', 'Lasso', 'LinearRegression'] :\n",
    "            prep_data = get_features(data, ['Morgan_Fingerprint 2048Bit 2rad'])\n",
    "            explainer = shap.LinearExplainer(model.named_steps['model'],model.named_steps['scaler'].transform(prep_data))\n",
    "        \n",
    "\n",
    "        data = get_SHAP_Morgan_attributions(data, 'Morgan_Fingerprint 2048Bit 2rad', 'smiles_std', model, explainer)\n",
    "        \n",
    "        Attribution_Colums.append('SHAP Attributions')\n",
    "        color_coding.append('#9C0D38')\n",
    "    \n",
    "    #RDKit\n",
    "    if \"Morgan\" in inspect.getsource(feature_function):\n",
    "        data['RDKit Attributions'] = data['smiles_std'].apply(lambda s: RDKit_attributor(s, SimilarityMaps.GetMorganFingerprint, model))\n",
    "        Attribution_Colums.append('RDKit Attributions')\n",
    "        color_coding.append('#758ECD')\n",
    "    if \"RDK\" in inspect.getsource(feature_function):\n",
    "        def fp_func(m, a):\n",
    "            return SimilarityMaps.GetRDKFingerprint(m, atomId=a, maxPath=7)\n",
    "        data['RDKit Attributions'] = data['smiles_std'].apply(lambda s: RDKit_attributor(s, fp_func, model))\n",
    "        Attribution_Colums.append('RDKit Attributions')\n",
    "        color_coding.append('#758ECD')\n",
    "\n",
    "    #Creat MMP database\n",
    "    colums_to_keep = Attribution_Colums + [Target_Column_Name]\n",
    "    data_MMPs = create_MMP_database(working_dir + \"data.smi\", working_dir ,data, colums_to_keep)\n",
    "    data_MMPs.to_csv(working_dir + \"MMPs_with_attributions.csv\", index=False)\n",
    "\n",
    "    #add predictions\n",
    "\n",
    "    #for 1\n",
    "    data_MMPs['Feature_1'] = data_MMPs['smiles_1'].apply(feature_function)\n",
    "    X_data_attributions_1 = get_features(data_MMPs, ['Feature_1'])\n",
    "    predictions_1 = model.predict(X_data_attributions_1)\n",
    "    data_MMPs['predictions_1'] = predictions_1\n",
    "\n",
    "    #for 2\n",
    "    data_MMPs['Feature_2'] = data_MMPs['smiles_2'].apply(feature_function)\n",
    "    X_data_attributions_1 = get_features(data_MMPs, ['Feature_2'])\n",
    "    predictions_1 = model.predict(X_data_attributions_1)\n",
    "    data_MMPs['predictions_2'] = predictions_1\n",
    "\n",
    "    #Add indices\n",
    "    data_MMPs[[\"unmatched_atom_index_1\", \"unmatched_atom_index_2\"]] = data_MMPs.apply(\n",
    "    lambda row: pd.Series(get_unmatched_atom_indices_fragments(row[\"smiles_1\"], row[\"smiles_2\"], row[\"constant\"])), axis=1)\n",
    "\n",
    "    #Add Plots\n",
    "\n",
    "    for attr_method, color in zip(Attribution_Colums, color_coding):\n",
    "        \n",
    "        r2_whole, r2_fragment, data_MMPs = get_r2_and_summed_data_attributions(data_MMPs, 'predictions_1', 'predictions_2', attr_method + '_1', attr_method + '_2', attr_method, 'unmatched_atom_index_1' , 'unmatched_atom_index_2')\n",
    "\n",
    "        plot_2D(['$r^2$(' + attr_method + ') = ' + str(f\"{r2_whole:.2f}\")], 'upper left', data_MMPs['delta_prediction'], data_MMPs['delta_sum_' + attr_method],\n",
    "                '$\\Delta$Predictions MMP', '$\\Delta$Attributions MMP (whole Mol)', working_dir + 'PREDvsCONTRIBUTIONSwhole' + attr_method + '.png', \n",
    "                color,\n",
    "                include_line=True, line_style='None')\n",
    "\n",
    "        plot_2D(['$r^2$(' + attr_method + ') = ' + str(f\"{r2_fragment:.2f}\")], 'upper left', data_MMPs['delta_prediction'], data_MMPs['delta_sum_fragment_contributions_' + attr_method],\n",
    "                '$\\Delta$Predictions MMP', '$\\Delta$Attributions MMP (Fragment)', working_dir + 'PREDvsCONTRIBUTIONSfragment' + attr_method + '.png', \n",
    "                color,\n",
    "                include_line=True, line_style='None')\n",
    "\n",
    "\n",
    "        data_MMPs['delta_target'] = data_MMPs[Target_Column_Name + '_1'] - data_MMPs[Target_Column_Name + '_2']\n",
    "\n",
    "        r2 = np.corrcoef(data_MMPs['delta_target'], data_MMPs['delta_sum_' + attr_method])[0,1]**2\n",
    "\n",
    "        plot_2D(['$r^2$(' + attr_method + ') = ' + str(f\"{r2:.2f}\")], 'upper left', data_MMPs['delta_target'], data_MMPs['delta_sum_' + attr_method],\n",
    "                '$\\Delta$Target MMP', '$\\Delta$Attributions MMP (whole Mol)', working_dir + 'EXPvsCONTRIBUTIONSwhole' + attr_method + '.png', \n",
    "                color,\n",
    "                include_line=True, line_style='None')\n",
    "        \n",
    "    #Analyse Locality\n",
    "\n",
    "    data_MMPs['unmatched_atom_index_1_with_neighbors'] = data_MMPs.apply(lambda row: get_neighbors(row['smiles_1'], row['unmatched_atom_index_1']), axis=1)\n",
    "    data_MMPs['unmatched_atom_index_2_with_neighbors'] = data_MMPs.apply(lambda row: get_neighbors(row['smiles_2'], row['unmatched_atom_index_2']), axis=1)\n",
    "\n",
    "    methods = {\n",
    "    'Atom': ('Atom Attributions_1_fix', 'Atom Attributions_2_fix', '#10384f', 'ATOM')}\n",
    "\n",
    "    if 'SHAP Attributions' in Attribution_Colums:\n",
    "        methods['SHAP'] = ('SHAP Attributions_1_fix', 'SHAP Attributions_2_fix', '#9C0D38', 'SHAP')\n",
    "    if 'RDKit Attributions' in Attribution_Colums:\n",
    "        methods['RDKit'] = ('RDKit Attributions_1_fix', 'RDKit Attributions_2_fix', '#758ECD', 'RDKIT')\n",
    "\n",
    "    for method, (attr1, attr2, color, label) in methods.items():\n",
    "        key1 = f'summ_unmatched_{method}_contributions_1_sphere'\n",
    "        key2 = f'summ_unmatched_{method}_contributions_2_sphere'\n",
    "        delta_key = f'delta_sum_fragment_{method}_contributions_sphere'\n",
    "\n",
    "        data_MMPs[key1] = get_unmatched_attributions(data_MMPs, attr1, 'unmatched_atom_index_1_with_neighbors')\n",
    "        data_MMPs[key2] = get_unmatched_attributions(data_MMPs, attr2, 'unmatched_atom_index_2_with_neighbors')\n",
    "        data_MMPs[delta_key] = data_MMPs[key1] - data_MMPs[key2]\n",
    "\n",
    "        r2 = np.corrcoef(data_MMPs['delta_prediction'], data_MMPs[delta_key])[0,1]**2\n",
    "\n",
    "        plot_2D(\n",
    "            [f'$r^2$({method}) = {r2:.2f}'], 'upper left',\n",
    "            data_MMPs['delta_prediction'],\n",
    "            data_MMPs[delta_key],\n",
    "            '$\\Delta$Predictions MMP',\n",
    "            '$\\Delta$Attributions MMP (Fragment+Neig)',\n",
    "            working_dir + label + 'attributor_NEIG.png',\n",
    "            color,\n",
    "            include_line=True,\n",
    "            line_style='None'\n",
    "        )\n",
    "    \n",
    "    #test/train dependency   \n",
    "    if model_available is None:\n",
    "        data_MMPs['set_1'] = data_MMPs['smiles_1'].isin(test['smiles_std']).map({True: 'test', False: 'train'})\n",
    "        data_MMPs['set_2'] = data_MMPs['smiles_2'].isin(test['smiles_std']).map({True: 'test', False: 'train'})\n",
    "\n",
    "        def compute_r2(data, label):\n",
    "            mask = data['set_1'].str.contains(label) & data['set_2'].str.contains(label)\n",
    "            filtered = data[mask]\n",
    "            for attr in Attribution_Colums:\n",
    "                r2 = np.corrcoef(\n",
    "                    filtered['delta_prediction'],\n",
    "                    filtered[f'delta_sum_{attr}']\n",
    "                )[0, 1] ** 2\n",
    "                print(f'{attr}_{label}:', r2)\n",
    "        \n",
    "        for split in ['train', 'test']:\n",
    "            compute_r2(data_MMPs, split)\n",
    "    \n",
    "    data_MMPs.to_csv(working_dir + \"Complete_Data.csv\", index=False)\n",
    "\n",
    "    return data_MMPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6aacd1",
   "metadata": {},
   "source": [
    "## Crippen logP ZINC (with ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-Rassmussen/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-Rassmussen/ZINC-Crippen.csv',\n",
    "     'No',\n",
    "     \"smiles\", \n",
    "     'crippen_logP',\n",
    "     model_available=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769915c",
   "metadata": {},
   "source": [
    "## Crippen logP MolNet (with ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-MolNet/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-MolNet/Lipophilicity-Crippen.csv',\n",
    "     'CMPD_CHEMBLID',\n",
    "     \"smiles\", \n",
    "     'crippen_logP',\n",
    "     model_available=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81038bcb",
   "metadata": {},
   "source": [
    "## LogP (Morgan + Random Forest Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Lipophilicity.csv',\n",
    "     'CMPD_CHEMBLID',\n",
    "     \"smiles\", \n",
    "     'exp',\n",
    "     model_available=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b309760",
   "metadata": {},
   "source": [
    "## PIXIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/data_complete_descriptors.txt',\n",
    "     'Structure Name',\n",
    "     \"SMILES Product\", \n",
    "     'LCAP Scheme 25',\n",
    "     model_available=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc50d8e",
   "metadata": {},
   "source": [
    "## Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf22fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/delaney-processed-Nr.csv',\n",
    "     \"Nr\",\n",
    "     \"smiles\", \n",
    "     'measured log solubility in mols per litre',\n",
    "     model_available=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fa0db",
   "metadata": {},
   "source": [
    "## TRPV1 bioactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/TRPV1-preprocessed-molpipeline-ChEMBL34.csv',\n",
    "     'Molecule ChEMBL ID',\n",
    "     \"Smiles\", \n",
    "     'logaritmic_activity',\n",
    "     model_available=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e18b14",
   "metadata": {},
   "source": [
    "## Factor Xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c294db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/FXa_Final_Public_Analogs_v4.csv',\n",
    "     'Structure No',\n",
    "     \"Smiles\", \n",
    "     'pKi',\n",
    "     model_available=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be9cd8",
   "metadata": {},
   "source": [
    "## AMES Mutagenicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9106049",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WISP('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/AMESwinter/', \n",
    "     '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/AMESwinter/ames.csv',\n",
    "     'Nr',\n",
    "     \"smiles\", \n",
    "     'label',\n",
    "     model_available=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51613933",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e77d41",
   "metadata": {},
   "source": [
    "#### Draw Molecules with Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import Image\n",
    "\n",
    "def draw_mol_with_attr(smiles, attr):\n",
    "    # Create a molecule (Ethanol)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Example array of values (e.g., from calculations or descriptors)\n",
    "    values = attr  # one value per atom\n",
    "\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(300, 300)\n",
    "\n",
    "    # Access the drawing options\n",
    "    options = drawer.drawOptions()\n",
    "\n",
    "    # Assign labels to specific atoms\n",
    "    for idx, value in enumerate(values):\n",
    "        options.atomLabels[idx] = f'{value:.2f}'\n",
    "\n",
    "    # Prepare and draw the molecule\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(drawer, mol)\n",
    "    drawer.FinishDrawing()\n",
    "\n",
    "    # Display in Jupyter Notebook\n",
    "    return Image(data=drawer.GetDrawingText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e53b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = [-0.08457939393939216, -0.11288095238094947, -0.09256190476190243, -0.13132476190475864, -0.08968412698412474, -0.1224875315840593, -0.24861746355684605, -0.22827270165208463, -0.3312164852607648, 0, -0.2023160544217648, -0.2023160544217648, -0.5672063259338717, -0.5382852805823986, -0.2781543876357507, -3.451325509177458, -3.3954510164551635, -3.1463015821594524, -3.116460049056739, -0.5999543250984525, -0.33972487852283145, -0.2782892857142778, -0.059171428571422366, -0.06663333333332677, -0.06109714285713488, -0.10144285714284962, -0.16538277056276424, -0.11197285714285025, -0.5424763964673487, -0.14360671525752874, -0.05259761904761706, -0.15345693877550762, -0.7976817460317353, -0.05821938775510005, -0.16587632653060944]\n",
    "draw_mol_with_attr('Cc1cn(C2CCCN(S(=O)(=O)c3ccc(C(=O)O)c(Oc4cccc(Cl)c4)c3)C2)c(=O)[nH]c1=O', attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07626c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = [-0.09669318181818208, -0.06688571428571463, -0.06145918367346963, -0.17660816326530654, -1.4515969620761084, -0.3008983432356228, -1.3369199865743835, -1.255931053024057, -1.3111168009536645, -1.460849684552024, -1.2496940391150446, -1.2163843488053536, -0.051957142857142924, -0.08889285714285744, -0.07538163265306132, -0.08704285714285698, -0.023373469387754833, -0.023373469387754895, -0.0805857142857146, -0.05498000000000016, -0.02898000000000034, -0.053114285714286114, -0.019050000000000372, -0.00872857142857153, -0.06918571428571452, -0.0419257142857147, -1.1732615079565476, -1.2053348531860308, 0.04665714285714235, -3.481891516224604, -3.41429544143642, -3.412031304240653, -3.2563618702445747]\n",
    "draw_mol_with_attr('CC(=O)Nc1ccc2c(c1)c(-c1cc(NC3CC3)n3ncc(C#N)c3n1)cn2CCC(=O)O', attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = [-0.3680934632034507, -0.6355469727891109, -0.9828836507936453, -0.6355469727891109, -0.3680934632034507, 1.28833698639456, 2.5815866233766194]\n",
    "draw_mol_with_attr('CCC(CC)CO', attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaebc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = [-0.6840650649350497, -1.5161986224489716, -2.521121428571412, -1.1637387012986953, -1.5161986224489716, -0.6840650649350497]\n",
    "draw_mol_with_attr('CCC(C)CC', attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955aec5",
   "metadata": {},
   "source": [
    "#### Draw Mol with Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7087f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = ['CC(C)(C)NC(=O)c1ncc(-c2ccc(C#N)cc2)o1', 'COC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1']\n",
    "for smi in smiles_list:\n",
    "    mol1 = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "    Chem.SanitizeMol(mol1)#to keep the explicit hydrogens\n",
    "    for atom in mol1.GetAtoms():\n",
    "        atom.SetProp('molAtomMapNumber', str(atom.GetIdx()))\n",
    "        \n",
    "    img = Draw.MolToImage(mol1)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b10593",
   "metadata": {},
   "outputs": [],
   "source": [
    "for smi in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)\n",
    "    \n",
    "    # Set atom map numbers just for visualization (optional)\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom.SetProp('molAtomMapNumber', str(atom.GetIdx()))\n",
    "    \n",
    "    # Get and print bond indices\n",
    "    print(f\"Bonds in: {smi}\")\n",
    "    for bond in mol.GetBonds():\n",
    "        bond_idx = bond.GetIdx()\n",
    "        begin_idx = bond.GetBeginAtomIdx()\n",
    "        end_idx = bond.GetEndAtomIdx()\n",
    "        print(f\"Bond {bond_idx}: {begin_idx} - {end_idx}\")\n",
    "    \n",
    "    img = Draw.MolToImage(mol)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5b922",
   "metadata": {},
   "source": [
    "#### Draw Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single molecule\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from IPython.display import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "smiles_list = ['CC(=O)OCN1C(=O)NC(c2ccccc2)(c2ccccc2)C1=O'\n",
    "               , 'CCCCCC(=O)OCN1C(=O)NC(c2ccccc2)(c2ccccc2)C1=O'\n",
    "                ]\n",
    "attr_list = [[0.0878029485291862, 0.18429023419510093, 0.004651627523322409, 0.0993537583585071, 0.16879923401475366, 0.36112685890584145, 0.47997814021490615, 0.5133176109505179, -0.1555064997665855, -0.5548520776948712, -0.025468312563339257, 0.37974263117933693, 0.2491675745533543, 0.09273801343718749, 0.2727059394215573, 0.1264606792172728, -0.025468312563339257, 0.37974263117933693, 0.2491675745533543, 0.09273801343718749, 0.2727059394215573, 0.1264606792172728, -0.11780881485086714, 0.6290783248481869]\n",
    "             , [-0.9578153449023629, -0.8851993337494158, -0.9503404452148967, -0.9969940568402514, -0.9524425781553383, -0.893346157518293, -0.45246240655922165, -0.6186790708403221, -0.7088811451528174, -0.669886992136049, -0.4721223080105039, 0.011893344695896932, -0.880420581582671, -1.2400228850140607, -0.80645822200806, -0.21699881390959047, -0.20136908485470856, -0.15630011556825388, -0.19265847840426514, -0.393178529021451, -0.80645822200806, -0.21699881390959047, -0.20136908485470856, -0.15630011556825388, -0.19265847840426514, -0.393178529021451, -0.35213751146935146, -0.09998442615988257]\n",
    "             ]\n",
    "\n",
    "for smiles, attributions in zip(smiles_list, attr_list):\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)#to keep the explicit hydrogens\n",
    "\n",
    "    custom_colors = ['#10384f', '#ffffff', '#9C0D38']#'#9C0D38', '#ffffff', '#10384f' oder (TU/Wien) #A43341', '#ffffff', '#3c629f'\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom\", custom_colors, N=256)\n",
    "\n",
    "    # Draw similarity map\n",
    "    d = Draw.MolDraw2DCairo(300, 300)\n",
    "    SimilarityMaps.GetSimilarityMapFromWeights(mol, attributions, draw2d=d, colorMap=custom_cmap)\n",
    "    d.FinishDrawing()\n",
    "\n",
    "    png = d.GetDrawingText()\n",
    "    display(Image(data=png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a43367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('index nitrogen:', attr_list[0][16])\n",
    "print('index methoxy:', attr_list[1][0], attr_list[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc540fa",
   "metadata": {},
   "source": [
    "#### Bit collisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles('CC(C)(C)NC(=O)c1ncc(-c2ccc(C#N)cc2)o1')\n",
    "bit_info = {}\n",
    "fp_1 = Chem.RDKFingerprint(m, maxPath=7, bitInfo=bit_info)\n",
    "\n",
    "keys_with_15 = [key for key, paths in bit_info.items() if any(15 in path for path in paths)]\n",
    "print(keys_with_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles('COC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1')\n",
    "bit_info = {}\n",
    "fp_2 = Chem.RDKFingerprint(m, maxPath=7, bitInfo=bit_info)\n",
    "\n",
    "keys_with_0 = [key for key, paths in bit_info.items() if any(0 in path for path in paths)]\n",
    "print(keys_with_0)\n",
    "\n",
    "keys_with_1 = [key for key, paths in bit_info.items() if any(1 in path for path in paths)]\n",
    "print(keys_with_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_elements = list(set(keys_with_15) & set(keys_with_1))\n",
    "print(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(21):\n",
    "    m = Chem.MolFromSmiles('CC(C)(C)NC(=O)c1ncc(-c2ccc(C#N)cc2)o1')\n",
    "    bit_info = {}\n",
    "    fp_1 = Chem.RDKFingerprint(m, maxPath=7, bitInfo=bit_info)\n",
    "\n",
    "    keys_with_15 = [key for key, paths in bit_info.items() if any(i in path for path in paths)]\n",
    "    print(i, len(keys_with_15\n",
    "                 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f250c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    m = Chem.MolFromSmiles('COC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1')\n",
    "    bit_info = {}\n",
    "    fp_1 = Chem.RDKFingerprint(m, maxPath=7, bitInfo=bit_info)\n",
    "\n",
    "    keys_with_15 = [key for key, paths in bit_info.items() if any(i in path for path in paths)]\n",
    "    print(i, len(keys_with_15\n",
    "                 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47075f39",
   "metadata": {},
   "source": [
    "#### What about the PIXIE atom attributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2df497",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"COC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1\" \n",
    "mutated_dict = {}\n",
    "\n",
    "for atom_idx, old_sym, new_sym, mutated in mutate_atoms(smiles):\n",
    "    if atom_idx not in mutated_dict:\n",
    "        mutated_dict[atom_idx] = []\n",
    "    if mutated:\n",
    "        mutated_dict[atom_idx].append(mutated)\n",
    "\n",
    "    print(f\"Atom {atom_idx} ({old_sym} ‚Üí {new_sym}): {mutated}\")\n",
    "\n",
    "#does the number of attributions have something to do with that? --> no\n",
    "#for i in mutated_dict:\n",
    "    #print('index:', i, '; no mutations', len(mutated_dict[i]))\n",
    "\n",
    "'''\n",
    "#is it a specific mutation?\n",
    "model = model = pickle.load(open(\"/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/model.pkl\", 'rb'))\n",
    "pred_origi = predictor_on_smiles(smiles, get_RDK_fingerprint, model)\n",
    "print(pred_origi)\n",
    "\n",
    "#m√ºssen tiefe pred sein bei C (0)\n",
    "mut_H = '[H]OC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1'\n",
    "mut_B= 'BOC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1'\n",
    "mut_N = 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)ON)cc2)o1'\n",
    "mut_O = 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OO)cc2)o1'\n",
    "mut_F= 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OF)cc2)o1'\n",
    "mut_si= 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)O[SiH3])cc2)o1'\n",
    "mut_P= 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OP)cc2)o1'\n",
    "mut_S= 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OS)cc2)o1'\n",
    "mut_Cl = 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OCl)cc2)o1'\n",
    "mut_Br = 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OBr)cc2)o1'\n",
    "mut_I= 'CC(C)(C)NC(=O)c1ncc(-c2ccc(C(=O)OI)cc2)o1'\n",
    "print(\"mutations\")\n",
    "#pred_mut_H =\n",
    "pred_mut_H = predictor_on_smiles(mut_H, get_RDK_fingerprint, model)\n",
    "pred_mut_N = predictor_on_smiles(mut_N, get_RDK_fingerprint, model)\n",
    "pred_mut_si = predictor_on_smiles(mut_si, get_RDK_fingerprint, model)\n",
    "pred_mut_I = predictor_on_smiles(mut_I, get_RDK_fingerprint, model)\n",
    "pred_mut_S = predictor_on_smiles(mut_S, get_RDK_fingerprint, model)\n",
    "pred_mut_Cl = predictor_on_smiles(mut_Cl, get_RDK_fingerprint, model)\n",
    "print(pred_mut_H, pred_mut_I, pred_mut_si, pred_mut_Cl, pred_mut_S, pred_mut_I)\n",
    "#si, S\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"COC(=O)c1ccc(-c2cnc(C(=O)NC(C)(C)C)o2)cc1\" \n",
    "mutated_dict = {}\n",
    "\n",
    "for atom_idx, old_sym, new_sym, mutated in mutate_atoms(smiles):\n",
    "    if atom_idx not in mutated_dict:\n",
    "        mutated_dict[atom_idx] = []\n",
    "    if mutated:\n",
    "        mutated_dict[atom_idx].append(mutated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70587614",
   "metadata": {},
   "source": [
    "#### Draw Molecules (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e28c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from IPython.display import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "import ast\n",
    "\n",
    "def gen_heatmap(data, index, output_dir, smiles_column, attribution_column, ID_column):\n",
    "    '''\n",
    "    Red is positive while blue is negative (to be consistant with PIXIE)\n",
    "    '''\n",
    "    smiles = data[smiles_column][index]\n",
    "    attributions = ast.literal_eval(data[attribution_column][index])\n",
    "    mol_id = data[ID_column][index]\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)#to keep the explicit hydrogens\n",
    "\n",
    "    custom_colors = ['#10384f', '#ffffff', '#9C0D38']#'#9C0D38', '#ffffff', '#10384f' oder (TU/Wien) #A43341', '#ffffff', '#3c629f'\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom\", custom_colors, N=256)\n",
    "\n",
    "    # Draw similarity map\n",
    "    d = Draw.MolDraw2DCairo(900, 900)\n",
    "    SimilarityMaps.GetSimilarityMapFromWeights(mol, attributions, draw2d=d, colorMap=custom_cmap)\n",
    "    d.FinishDrawing()\n",
    "\n",
    "    # Define and write output path\n",
    "    filename = f\"{mol_id}_{attribution_column}.png\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(d.GetDrawingText())\n",
    "\n",
    "    return Image(filename=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb107636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LCAP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data.csv')\n",
    "data_LCAP['Atom Attributions_2_fix']\n",
    "#max_abs_value = data_LCAP['Atom Attributions_1_fix'].apply(lambda lst: max(map(abs, lst))).max()\n",
    "#print(max_abs_value)\n",
    "\n",
    "evaluated_series = data_LCAP['Atom Attributions_1_fix'].apply(ast.literal_eval)\n",
    "\n",
    "# Find max absolute value\n",
    "max_abs_value = evaluated_series.apply(lambda lst: max(map(abs, lst))).max()\n",
    "print(max_abs_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6489c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LCAP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data.csv')\n",
    "for index, row in data_LCAP.iterrows():\n",
    "    gen_heatmap(\n",
    "        data_LCAP,\n",
    "        index,\n",
    "        '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/HeatMaps/',\n",
    "        'smiles_2',\n",
    "        'SHAP Attributions_2_fix',\n",
    "        'ID_2'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the custom colormap\n",
    "colors = ['#10384f', '#ffffff', '#9C0D38']\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_diverging\", colors)\n",
    "\n",
    "# Create the colorbar\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "plt.imshow(gradient, aspect='auto', cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "from IPython.display import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "import ast\n",
    "from matplotlib.colors import TwoSlopeNorm, LinearSegmentedColormap\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "def generate_heatmap(data, index, output_dir, smiles_column, attribution_column, ID_column, task_type):\n",
    "    '''\n",
    "    Red is positive while blue is negative (to be consistant with PIXIE)\n",
    "    '''\n",
    "    smiles = data[smiles_column][index]\n",
    "    attributions = data[attribution_column][index]#.fillna(0)#ast.literal_eval()\n",
    "    attributions = [0 if isinstance(x, float) and math.isnan(x) else x for x in attributions]\n",
    "    mol_id = data[ID_column][index]\n",
    "\n",
    "    #vmax = data[attribution_column].abs().max() * 0.7\n",
    "    #evaluated_series = data[attribution_column].apply(ast.literal_eval)\n",
    "    if task_type == 'regression':\n",
    "        vmax = data[attribution_column].apply(lambda lst: max(map(abs, lst))).max() * 0.7\n",
    "    if task_type == 'classification':\n",
    "        vmax = 0.7\n",
    "    #evaluated_series = data[attribution_column]\n",
    "    #vmax = evaluated_series.apply(lambda lst: max(map(abs, list(lst)))).max() * 0.7\n",
    "    #vmax = evaluated_series.apply(lambda lst: max(map(abs, lst))).max() * 0.7\n",
    "    vmin = -vmax\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)#to keep the explicit hydrogens\n",
    "\n",
    "    # Draw similarity map\n",
    "    atom_colors = {}\n",
    "    for atom in mol.GetAtoms():\n",
    "        idx = atom.GetIdx()\n",
    "        weight = attributions[idx] if idx < len(attributions) else 0.0  # Default weight as 0.0 if atom index not found\n",
    "        color, cmap = get_color(weight, '#10384f', '#ffffff', '#9C0D38', vmin, vmax)\n",
    "        atom_colors[idx] = color\n",
    "        atom.SetProp(\"_displayColor\", ','.join(map(str, color)))\n",
    "    \n",
    "    d = Draw.MolDraw2DCairo(1800, 1800)\n",
    "    d.DrawMolecule(mol,highlightAtoms=list(atom_colors.keys()),highlightAtomColors=atom_colors)#, highlightBonds=[]\n",
    "    d.FinishDrawing()\n",
    "\n",
    "    # Create a color bar\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "    norm = TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "    cbar = ColorbarBase(ax, norm=norm, cmap=cmap, orientation='horizontal')  #\n",
    "\n",
    "    tick_positions = [vmin, vmax]\n",
    "    tick_labels = [vmin, vmax]\n",
    "    cbar.set_ticks(tick_positions)\n",
    "    cbar.set_ticklabels(tick_labels)\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, 'Legend.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Define and write output path\n",
    "    filename = f\"{mol_id}_{attribution_column}.png\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(d.GetDrawingText())\n",
    "\n",
    "    return Image(filename=output_path)\n",
    "\n",
    "def get_color(weight, neg_color, neut_color, pos_color, vmin, vmax):\n",
    "    \"\"\"\n",
    "    Creates a custom colormap from black to red and colors the bonds accordingly.\n",
    "\n",
    "    Keyword arguments:\n",
    "    -- weight: Weight of the bond to be colored.\n",
    "    -- neg_color: Color with which the decrease of the target variable should be described.\n",
    "    -- neut_color: Color with which no influence of the target variable should be described.\n",
    "    -- pos_color: Color with which the increase of the target variable should be described.\n",
    "    -- vmin: Lower bound to normalize the colourcoding on the bond weights.\n",
    "    -- vmax: Upper bound to normalize the colourcoding on the bond weights.\n",
    "\n",
    "    Returns:\n",
    "    -- tuple(rgba[:3]): Colour of the bond.\n",
    "    -- cmap: Custom color map.\n",
    "    \"\"\"\n",
    "    norm = TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "    colors = [neg_color, neut_color, pos_color] # 'dimgray'\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "    rgba = cmap(norm(weight))\n",
    "    return tuple(rgba[:3]), cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LCAP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data.csv')\n",
    "for index, row in data_LCAP.iterrows():\n",
    "    generate_heatmap(\n",
    "        data_LCAP,\n",
    "        index,\n",
    "        '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/HeatMaps/',\n",
    "        'smiles_2',\n",
    "        'Atom Attributions_2_fix',\n",
    "        'ID_2',\n",
    "        'classification'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62001d",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def correlation_contrib(data, contrib_colum):\n",
    "    # Standardize both columns\n",
    "    data['z_pred'] = zscore(data['delta_prediction'])\n",
    "    data['z_attr'] = zscore(data[contrib_colum])\n",
    "\n",
    "    # Pointwise contribution to Pearson correlation\n",
    "    data['correlation_contrib' + contrib_colum] = data['z_pred'] * data['z_attr']\n",
    "    return data\n",
    "\n",
    "    # Best (most positively contributing) datapoints\n",
    "    #most_positively_correlated = data.nlargest(10, 'correlation_contrib')\n",
    "\n",
    "    # Worst (most negatively contributing) datapoints\n",
    "    #most_negatively_correlated = data.nsmallest(10, 'correlation_contrib')\n",
    "\n",
    "    # Show results\n",
    "    #print(\"Most positively correlated datapoints:\")\n",
    "    #print(most_positively_correlated[['delta_prediction', 'delta_sum_fragment_contributions_Atom Attributions', 'correlation_contrib']])\n",
    "    #print(most_positively_correlated[['ID_1', 'ID_2']])\n",
    "\n",
    "    #print(\"\\nMost negatively correlated datapoints:\")\n",
    "    #print(most_negatively_correlated[['delta_prediction', 'delta_sum_fragment_contributions_Atom Attributions', 'correlation_contrib']])\n",
    "    #print(most_negatively_correlated[['ID_1', 'ID_2']])\n",
    "\n",
    "\n",
    "def get_residuals(data, contrib_colum):\n",
    "    X = data[['delta_prediction']].values.reshape(-1, 1)\n",
    "    Y = data[contrib_colum].values.reshape(-1, 1)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    data['Y_pred'] = model.predict(X)\n",
    "    data['residual' + contrib_colum] = data[contrib_colum] - data['Y_pred']\n",
    "    data['abs_residual' + contrib_colum] = data['residual' + contrib_colum].abs()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LCAP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions']\n",
    "for i in columns_of_interest:\n",
    "    get_residuals(data_LCAP, i)\n",
    "\n",
    "data_LCAP.to_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/Complete_Data_correlation_contrib.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_SHAP Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_SHAP Attributions']\n",
    "for i in columns_of_interest:\n",
    "    get_residuals(data_logP, i)\n",
    "\n",
    "data_logP.to_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data_correlation_contrib.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sol = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions']\n",
    "for i in columns_of_interest:\n",
    "    get_residuals(data_sol, i)\n",
    "\n",
    "data_sol.to_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/Complete_Data_correlation_contrib.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TRPV1 = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_SHAP Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_SHAP Attributions']\n",
    "for i in columns_of_interest:\n",
    "    get_residuals(data_TRPV1, i)\n",
    "\n",
    "data_TRPV1.to_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/Complete_Data_correlation_contrib.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11b43b",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def do_confusion_matrix(data, contrib_colum, dir):\n",
    "    y_true = (data['delta_prediction'] > 0).astype(int)\n",
    "    y_pred = (data[contrib_colum] > 0).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(contrib_colum + f\" Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Attr Negative', 'Attr Positive'],\n",
    "            yticklabels=['Pred Negative', 'Pred Positive'])\n",
    "    plt.xlabel('Attributions')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(contrib_colum)\n",
    "    plt.savefig(dir + contrib_colum + '_confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "data_AMES = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/AMESwinter/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions']\n",
    "for i in columns_of_interest:\n",
    "    do_confusion_matrix(data_AMES, i, '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/AMESwinter/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def do_confusion_matrix(data, contrib_colum, dir):\n",
    "    y_true = (data['delta_prediction'] > 0).astype(int)\n",
    "    y_pred = (data[contrib_colum] > 0).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(contrib_colum + f\" Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    '''\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pred Negative', 'Pred Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(contrib_colum)\n",
    "    #plt.savefig(dir + contrib_colum + '_confusion_matrix.png')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LCAP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions']\n",
    "for i in columns_of_interest:\n",
    "    do_confusion_matrix(data_LCAP, i, '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/PIXIE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_SHAP Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_SHAP Attributions']\n",
    "for i in columns_of_interest:\n",
    "    do_confusion_matrix(data_logP, i, '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Lipophilicity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46673a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sol = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions']\n",
    "for i in columns_of_interest:\n",
    "    do_confusion_matrix(data_sol, i, '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/ESOLmoleculeNET/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TRPV1 = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/Complete_Data.csv')\n",
    "columns_of_interest = ['delta_sum_Atom Attributions', \n",
    "                       'delta_sum_RDKit Attributions',\n",
    "                       'delta_sum_SHAP Attributions',\n",
    "                       'delta_sum_fragment_contributions_Atom Attributions', \n",
    "                       'delta_sum_fragment_contributions_RDKit Attributions',\n",
    "                       'delta_sum_fragment_contributions_SHAP Attributions']\n",
    "for i in columns_of_interest:\n",
    "    do_confusion_matrix(data_TRPV1, i, '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/TRPV1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = (data['delta_prediction'] > 0).astype(int)\n",
    "y_pred = (data['delta_sum_fragment_contributions_Atom Attributions'] > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "#[[TN, FP],\n",
    "# [FN, TP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a91e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pred Negative', 'Pred Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74f91f",
   "metadata": {},
   "source": [
    "## Analyze Error on Constant Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d813eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_attributions = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/Complete_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "data_attributions['unmatched_atom_index_1'] = data_attributions['unmatched_atom_index_1'].apply(ast.literal_eval)\n",
    "data_attributions['unmatched_atom_index_2'] = data_attributions['unmatched_atom_index_2'].apply(ast.literal_eval)\n",
    "data_attributions['RDKit Attributions_1'] = data_attributions['RDKit Attributions_1'].apply(ast.literal_eval)\n",
    "data_attributions['RDKit Attributions_2'] = data_attributions['RDKit Attributions_2'].apply(ast.literal_eval)\n",
    "data_attributions['RDKit Attributions_1_fix'] = data_attributions['RDKit Attributions_1_fix'].apply(ast.literal_eval)\n",
    "data_attributions['RDKit Attributions_2_fix'] = data_attributions['RDKit Attributions_2_fix'].apply(ast.literal_eval)\n",
    "#data_attributions['Atom Attributions_1'] = data_attributions['Atom Attributions_1'].apply(ast.literal_eval)\n",
    "#data_attributions['Atom Attributions_2'] = data_attributions['Atom Attributions_2'].apply(ast.literal_eval)\n",
    "data_attributions['Atom Attributions_1_fix'] = data_attributions['Atom Attributions_1_fix'].apply(ast.literal_eval)\n",
    "data_attributions['Atom Attributions_2_fix'] = data_attributions['Atom Attributions_2_fix'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d55ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attributions['const_indices_1'] = data_attributions.apply(lambda row: get_unselected_atom_indices(row['smiles_1'], row['unmatched_atom_index_1']), axis=1)\n",
    "data_attributions['const_indices_2'] = data_attributions.apply(lambda row: get_unselected_atom_indices(row['smiles_2'], row['unmatched_atom_index_2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_const, data_attributions = get_r2_and_summed_data_attributions_const(data_attributions, 'predictions_1', 'predictions_2', 'RDKit Attributions_1', 'RDKit Attributions_2', \"RDKit_Attributions\", 'const_indices_1' , 'const_indices_2')\n",
    "\n",
    "plot_2D(['$r^2$(RDKit) = ' + str(f\"{r2_const:.2f}\")], 'upper left', data_attributions['delta_prediction'], data_attributions['delta_sum_const_contributions_RDKit_Attributions'],\n",
    "        '$\\Delta$Predictions MMP', '$\\Delta$Attributions MMP (Constant)', '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/PREDvsCONTRIBUTIONSconstRDKITattributor.png', \n",
    "        '#758ECD',\n",
    "        include_line=True, line_style='None')\n",
    "\n",
    "r2_const, data_attributions = get_r2_and_summed_data_attributions_const(data_attributions, 'predictions_1', 'predictions_2', 'Atom Attributions_1', 'Atom Attributions_2', \"Atom_Attributions\", 'const_indices_1' , 'const_indices_2')\n",
    "\n",
    "plot_2D(['$r^2$(XSMILES) = ' + str(f\"{r2_const:.2f}\")], 'upper left', data_attributions['delta_prediction'], data_attributions['delta_sum_const_contributions_Atom_Attributions'],\n",
    "        '$\\Delta$Predictions MMP', '$\\Delta$Attributions MMP (Constant)', '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/PREDvsCONTRIBUTIONSconstATOMattributor.png', \n",
    "        '#10384f',\n",
    "        include_line=True, line_style='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_histogram_one_dataset(data, colum_of_interest, label, color, attr_method, save_dir):\n",
    "\n",
    "    #get standard deviation\n",
    "    std_dev = np.std(data[colum_of_interest])\n",
    "\n",
    "    # color\n",
    "    base_color = mcolors.to_rgba(color) \n",
    "    color_with_alpha = base_color[:3] + (0.5,)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data[colum_of_interest], bins=30, color=color_with_alpha, edgecolor=color, label=f\"{attr_method} \\n(Standard Deviation: {std_dev:.2f})\")  \n",
    "    \n",
    "    plt.rcParams['font.family'] = 'arial'\n",
    "    plt.xlabel(label, fontsize=18)\n",
    "    plt.ylabel('MMP Count', fontsize=18)\n",
    "    plt.legend(fontsize=16, loc='upper left')\n",
    "\n",
    "\n",
    "    # Save plot\n",
    "    filename = f\"{attr_method.replace(' ', '_').lower()}_histogram.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Histogram saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fee107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_const_histogram(data_attributions, 'RDKit_Attributions', '#758ECD', '/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b0ad",
   "metadata": {},
   "source": [
    "## MorganGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_morgan(smiles, coefficients_total):\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)#to keep the explicit hydrogens\n",
    "\n",
    "    bit_info = {}\n",
    "    #fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048, bitInfo=bit_info)\n",
    "    generator = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "    fp = generator.GetFingerprint(mol, bitInfo=bit_info)\n",
    "\n",
    "    #print(bit_info)\n",
    "\n",
    "    atom_weights = calculate_atom_weights(mol, coefficients_total, bit_info)\n",
    "\n",
    "    return atom_weights\n",
    "\n",
    "def get_SHAP_Morgan_attributions(data, feature_column, smiles_column, model, explainer):\n",
    "    prep_data = get_features(data, [feature_column])\n",
    "\n",
    "    shap_values = explainer.shap_values(model.named_steps['scaler'].transform(prep_data))\n",
    "    print(\"Shap values are calculated.\")\n",
    "\n",
    "    atom_weights_list = []\n",
    "\n",
    "    for nr, (index, row) in enumerate(data.iterrows(), 1):\n",
    "        smiles = row[smiles_column]\n",
    "        shap_nr = nr - 1\n",
    "        atom_weights = weights_morgan(smiles, shap_values[shap_nr])\n",
    "        atom_weights_values = list(atom_weights.values())\n",
    "        atom_weights_list.append(atom_weights_values)\n",
    "\n",
    "    data['SHAP Attributions'] = atom_weights_list\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_morgan_fingerprint(smiles):\n",
    "    \"\"\"\n",
    "    Calculates the Morgan Fingerprint (2028 bits, radius of 2) for the input smiles.\n",
    "\n",
    "    Keyword arguments:\n",
    "    -- smiles: Smiles for the which the fingerprint should be calculated.\n",
    "\n",
    "    Returns:\n",
    "    -- fingerprint: Morgan Fingerprint as array to the respective smiles.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)#to keep the explicit hydrogens\n",
    "    \n",
    "    if mol is not None:\n",
    "        generator = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "        fingerprint = generator.GetFingerprint(mol)\n",
    "        #fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        fingerprint = fingerprint.ToBitString()\n",
    "        fingerprint = np.array(list(fingerprint))\n",
    "        return fingerprint\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_attributions = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/Complete_Data.csv')\n",
    "data_attributions['Morgan_Fingerprint 2048Bit 2rad'] = data_attributions['smiles_1'].apply(get_morgan_fingerprint)\n",
    "model = pickle.load(open('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/FactorXa-Bail2023/' + \"model.pkl\", 'rb'))\n",
    "explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "get_SHAP_Morgan_attributions(data_attributions, 'Morgan_Fingerprint 2048Bit 2rad', 'smiles_1', model, explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967a19f",
   "metadata": {},
   "source": [
    "# Calculate Crippen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP = pd.read_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-Rassmussen/ZINC_250k.smi', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP.columns = ['smiles']  # Change 'YourColumnName' to whatever you prefer\n",
    "\n",
    "# Add a column with row numbers starting from 1\n",
    "data_logP.insert(0, 'No', range(1, len(data_logP) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e12223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Crippen\n",
    "\n",
    "def calculate_logp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "    Chem.SanitizeMol(mol)\n",
    "    if mol:\n",
    "        return Crippen.MolLogP(mol)\n",
    "    return None\n",
    "\n",
    "data_logP[\"crippen_logP\"] = data_logP[\"smiles\"].apply(calculate_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logP.to_csv('/Users/kerrinjanssen/Nextcloud/PhD/Bayer/XAI/Crippen-Rassmussen/ZINC-Crippen.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98417a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
